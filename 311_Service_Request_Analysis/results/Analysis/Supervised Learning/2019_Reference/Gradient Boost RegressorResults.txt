Gradient Boost Regressor Results on Test Data=======================================RootMeanSquared Error: 188.6092145890971R2: 0.3602433312262053320 Sample Records for Predictions[Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 3.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=749.1591666666667, prediction=497.862044726488), Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 8.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=137.35666666666665, prediction=360.8570802615918), Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 12.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=240.2275, prediction=351.08637606025445), Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 18.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=379.5572222222222, prediction=353.05585448426046), Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 18.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=524.2675, prediction=353.05585448426046), Row(features=SparseVector(32, {0: 1.0, 1: 1.0, 2: 18.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=524.2675, prediction=353.05585448426046), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 10.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=168.015, prediction=364.15515780383583), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 10.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=503.63972222222225, prediction=364.15515780383583), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 11.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=167.26305555555555, prediction=360.1041962054152), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 12.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=181.2277777777778, prediction=360.1041962054152), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 13.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=54.791111111111114, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 15.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=153.44361111111112, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 16.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=102.09194444444445, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 16.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=102.09194444444445, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 16.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=363.8305555555556, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 18.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=146.17777777777778, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 18.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=362.39222222222224, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 2.0, 2: 20.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=148.16694444444445, prediction=362.0736746294212), Row(features=SparseVector(32, {0: 1.0, 1: 3.0, 2: 2.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=106.47638888888889, prediction=506.87986487164875), Row(features=SparseVector(32, {0: 1.0, 1: 3.0, 2: 9.0, 3: 1.0, 9: 1.0, 13: 1.0, 30: 1.0}), label=259.32972222222224, prediction=369.87490040675254)]Feature Importance - (32,[0,1,2,3,4,5,6,9,10,11,12,13,17,18,19,20,22,24,25,27,28,29,30,31],[0.2525325900069099,0.060506074394576156,0.16472167089122072,0.02248744484440124,0.012848634325412413,0.007879711303824746,0.0015398156942429326,0.06583746538713049,0.047026685032748844,0.0779678772036789,0.005813495258666568,0.059695974925285625,0.01251480198181167,0.0011325090622414573,0.00902138122860879,0.03312689677168941,0.003869291719222031,0.04598069258609726,0.07743180058973843,9.459907510288829e-06,0.001873995847259809,0.023139659145820963,0.002320307115763527,0.010721764776137923])Best MaxIteration Parameter - 20Number of Decision Trees - 20Decision Trees Created - [DecisionTreeRegressionModel (uid=dtr_a9e491bfb784) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_e56afe40e42e) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_7d30738783ea) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_621f879d9315) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_d04e5aaa1315) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_565da13238f7) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_52859cb74518) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_24f9f0035a10) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_e4b13c90af91) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_6e66b6764848) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_4db590520190) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_2a12f04b53d7) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_ea93c2658a2e) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_39bdffdd59f1) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_0911b6e90aa8) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_b2062ece766f) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_1f744f3a1c4e) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_8a167ea6db33) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_fe0669420cc8) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_a61d79b9065f) of depth 5 with 63 nodes]Decision Trees Weights - [1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
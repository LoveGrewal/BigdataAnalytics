{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyspark.sql.functions as F\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col, count, isnull, upper, substring, to_timestamp, unix_timestamp, lit, avg\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, Evaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"NYC 311 Data Analysis\") \\\n",
    "        .config('spark.sql.codegen.wholeStage', 'false') \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreparation(csvPath=\"data/New_Data/311_Cleaned_Data_2019.csv\"):\n",
    "    spark = init_spark()\n",
    "    nyc_311_df_2019 = spark.read.csv(csvPath, inferSchema=True, header=True)\n",
    "    nyc_2019 = nyc_311_df_2019.drop('created_date')\n",
    "    \n",
    "    # Code to make categorical data into columns (Agenct, Borough, Complaint Type, Channel) \n",
    "    agencies = nyc_2019.select(\"Agency\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    boroughs = nyc_2019.select(\"Borough\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    complain_types = nyc_2019.select(\"complaint_type\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    open_data_channel_types = nyc_2019.select(\"open_data_channel_type\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    # filling new column with value 1 if belong to particular category\n",
    "    agencies_expr = [F.when(F.col(\"Agency\") == ty, 1).otherwise(0).alias(\"e_AGENCY_\" + ty) for ty in agencies]\n",
    "    boroughs_expr = [F.when(F.col(\"Borough\") == code, 1).otherwise(0).alias(\"e_BOROUGH_\" + code) for code in boroughs]\n",
    "    complain_types_expr = [F.when(F.col(\"complaint_type\") == ty, 1).otherwise(0).alias(\"e_COMPLAIN_TYPE_\" + ty) for ty in complain_types]\n",
    "    open_data_channel_types_expr = [F.when(F.col(\"open_data_channel_type\") == code, 1).otherwise(0).alias(\"e_CHANNEL_TYPE_\" + code) for code in open_data_channel_types]\n",
    "    \n",
    "    nyc_2019_new = nyc_2019.select(\"Creation_Month\", \"Creation_Day\", \"Creation_Hour\", 'time_to_resolve_in_hrs', *agencies_expr+boroughs_expr+complain_types_expr+open_data_channel_types_expr)\n",
    "    \n",
    "    nyc_2019_new.cache()\n",
    "    # Save new csv for prepared data to be used in model Learning\n",
    "    nyc_2019_new.coalesce(1).write.format('com.databricks.spark.csv').save('311 Learning Data.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Creation_Month: integer (nullable = true)\n",
      " |-- Creation_Day: integer (nullable = true)\n",
      " |-- Creation_Hour: integer (nullable = true)\n",
      " |-- time_to_resolve_in_hrs: double (nullable = true)\n",
      " |-- e_AGENCY_HPD: integer (nullable = true)\n",
      " |-- e_AGENCY_NYPD: integer (nullable = true)\n",
      " |-- e_AGENCY_DEP: integer (nullable = true)\n",
      " |-- e_AGENCY_DSNY: integer (nullable = true)\n",
      " |-- e_AGENCY_DOITT: integer (nullable = true)\n",
      " |-- e_BOROUGH_UNSPECIFIED: integer (nullable = true)\n",
      " |-- e_BOROUGH_QUEENS: integer (nullable = true)\n",
      " |-- e_BOROUGH_BROOKLYN: integer (nullable = true)\n",
      " |-- e_BOROUGH_BRONX: integer (nullable = true)\n",
      " |-- e_BOROUGH_MANHATTAN: integer (nullable = true)\n",
      " |-- e_BOROUGH_STATEN ISLAND: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_UNSANITARY CONDITION: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Illegal Parking: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Noise - Residential: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Noise - Commercial: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Water System: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Blocked Driveway: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_HEAT/HOT WATER: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_PAINT/PLASTER: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Noise: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Request Large Bulky Item Collection: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_PLUMBING: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_WATER LEAK: integer (nullable = true)\n",
      " |-- e_COMPLAIN_TYPE_Noise - Street/Sidewalk: integer (nullable = true)\n",
      " |-- e_CHANNEL_TYPE_MOBILE: integer (nullable = true)\n",
      " |-- e_CHANNEL_TYPE_UNKNOWN: integer (nullable = true)\n",
      " |-- e_CHANNEL_TYPE_OTHER: integer (nullable = true)\n",
      " |-- e_CHANNEL_TYPE_PHONE: integer (nullable = true)\n",
      " |-- e_CHANNEL_TYPE_ONLINE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = init_spark()\n",
    "nyc_311_df_2019 = spark.read.csv(\"data/New_Data/311 Learning Data.csv\", inferSchema=True, header=True)\n",
    "nyc_311_df_2019.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature vector\n",
    "def getLearningDataWithFeatureVector(learningData= \"data/New_Data/311 Learning Data.csv\"):\n",
    "    nyc_311_df_2019 = spark.read.csv(learningData, inferSchema=True, header=True)\n",
    "    assembler = VectorAssembler(inputCols=['Creation_Month', 'Creation_Day','Creation_Hour','e_AGENCY_HPD', 'e_AGENCY_NYPD', 'e_AGENCY_DEP', 'e_AGENCY_DSNY', 'e_AGENCY_DOITT', 'e_BOROUGH_UNSPECIFIED', 'e_BOROUGH_BROOKLYN', 'e_BOROUGH_BRONX', 'e_BOROUGH_MANHATTAN', 'e_BOROUGH_STATEN ISLAND', 'e_COMPLAIN_TYPE_UNSANITARY CONDITION', 'e_COMPLAIN_TYPE_Illegal Parking', 'e_COMPLAIN_TYPE_Noise - Residential', 'e_COMPLAIN_TYPE_Noise - Commercial', 'e_COMPLAIN_TYPE_Water System', 'e_COMPLAIN_TYPE_Blocked Driveway', 'e_COMPLAIN_TYPE_HEAT/HOT WATER', 'e_COMPLAIN_TYPE_PAINT/PLASTER', 'e_COMPLAIN_TYPE_PAINT/PLASTER', 'e_COMPLAIN_TYPE_Noise', 'e_COMPLAIN_TYPE_Request Large Bulky Item Collection', 'e_COMPLAIN_TYPE_PLUMBING', 'e_COMPLAIN_TYPE_WATER LEAK', 'e_COMPLAIN_TYPE_Noise - Street/Sidewalk', 'e_CHANNEL_TYPE_MOBILE', 'e_CHANNEL_TYPE_UNKNOWN', 'e_CHANNEL_TYPE_OTHER', 'e_CHANNEL_TYPE_PHONE', 'e_CHANNEL_TYPE_ONLINE'],\n",
    "    outputCol=\"features\")\n",
    "    output = assembler.transform(nyc_311_df_2019)\n",
    "    X = output.select(\"features\", \"time_to_resolve_in_hrs\").withColumnRenamed(\"time_to_resolve_in_hrs\",\"label\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithLinearRegressor(X):\n",
    "    train, test = X.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "    # TrainValidationSplit will try all combinations of values and determine best model using\n",
    "    # the evaluator.\n",
    "    paramGrid = ParamGridBuilder()\\\n",
    "        .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "        .addGrid(lr.fitIntercept, [False, True])\\\n",
    "        .addGrid(lr.maxIter, [100, 150, 200])\\\n",
    "        .build()\n",
    "\n",
    "    # In this case the estimator is simply the linear regression.\n",
    "    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "    tvs = CrossValidator(estimator=lr,\n",
    "                               estimatorParamMaps=paramGrid,\n",
    "                               evaluator=RegressionEvaluator(),)\n",
    "\n",
    "    # Run TrainValidationSplit, and choose the best set of parameters.\n",
    "    model = tvs.fit(train)\n",
    "\n",
    "    # Make predictions on test data. model is the model with combination of parameters\n",
    "    # that performed best.\n",
    "    model.transform(test)\\\n",
    "        .select(\"features\", \"label\", \"prediction\")\\\n",
    "        .show()\n",
    "    print(\"Linear Regression Result\")\n",
    "    print(\"RootMeanSquare:\")\n",
    "    print(model.bestModel.summary.rootMeanSquaredError)\n",
    "    print(\"R2:\")\n",
    "    print(model.bestModel.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrainingLinearRegressor():\n",
    "    trainWithLinearRegressor(getLearningDataWithFeatureVector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|             label|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|(32,[0,1,2,3,9,13...| 749.1591666666667|420.03701095705264|\n",
      "|(32,[0,1,2,3,9,13...|1039.5022222222221| 419.2431538561919|\n",
      "|(32,[0,1,2,3,9,13...|          312.7975| 419.5869840435109|\n",
      "|(32,[0,1,2,3,9,13...| 144.8177777777778|421.99379535474367|\n",
      "|(32,[0,1,2,3,9,13...|            429.79|422.33762554206265|\n",
      "|(32,[0,1,2,3,9,13...|374.62583333333333| 422.6814557293816|\n",
      "|(32,[0,1,2,3,9,13...|20.548333333333332|423.02528591670057|\n",
      "|(32,[0,1,2,3,9,13...|153.44361111111112| 424.0567764786575|\n",
      "|(32,[0,1,2,3,9,13...| 464.6483333333333|419.13695712996906|\n",
      "|(32,[0,1,2,3,9,13...| 98.28472222222223| 421.1999382538829|\n",
      "|(32,[0,1,2,3,9,13...| 91.24972222222222|421.88759862852083|\n",
      "|(32,[0,1,2,3,9,13...|305.48555555555555|422.57525900315875|\n",
      "|(32,[0,1,2,3,9,13...|             85.68|422.91908919047773|\n",
      "|(32,[0,1,2,3,9,13...| 351.1188888888889|422.91908919047773|\n",
      "|(32,[0,1,2,3,9,13...| 607.5527777777778| 423.2629193777967|\n",
      "|(32,[0,1,2,3,9,13...| 242.7813888888889| 423.6067495651157|\n",
      "|(32,[0,1,2,3,9,13...|318.36861111111114| 423.6067495651157|\n",
      "|(32,[0,1,2,3,9,13...|458.44166666666666| 423.6067495651157|\n",
      "|(32,[0,1,2,3,9,13...|149.47833333333332| 424.2944099397537|\n",
      "|(32,[0,1,2,3,9,13...|338.70972222222224| 424.6382401270726|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Linear Regression Result\n",
      "RootMeanSquare:\n",
      "198.45433617137633\n",
      "R2:\n",
      "0.301762716535108\n"
     ]
    }
   ],
   "source": [
    "startTrainingLinearRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithRandomForest(X):\n",
    "    train, test = X.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "    # TrainValidationSplit will try all combinations of values and determine best model using\n",
    "    # the evaluator.\n",
    "    paramGrid = ParamGridBuilder()\\\n",
    "        .addGrid(rf.numTrees, [35, 50]) \\\n",
    "        .addGrid(rf.maxDepth, [7, 10])\\\n",
    "        .build()\n",
    "\n",
    "    # In this case the estimator is simply the linear regression.\n",
    "    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "    tvs = CrossValidator(estimator=rf,\n",
    "                               estimatorParamMaps=paramGrid,\n",
    "                               evaluator=RegressionEvaluator())\n",
    "\n",
    "    # Run TrainValidationSplit, and choose the best set of parameters.\n",
    "    model = tvs.fit(train)\n",
    "\n",
    "    # Make predictions on test data. model is the model with combination of parameters\n",
    "    # that performed best.\n",
    "    predictions = model.transform(test)\n",
    "    predictions.select(\"features\", \"label\", \"prediction\")\\\n",
    "        .show()\n",
    "    # return model\n",
    "    #print(\"Linear Regression Result\")\n",
    "    #print(\"RootMeanSquare:\")\n",
    "    #print(model.bestModel.summary.rootMeanSquaredError)\n",
    "    #print(\"R2:\")\n",
    "    #print(model.bestModel.summary.r2)\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2 = evaluator.evaluate(predictions)\n",
    "    print(\"R2 (R2) on test data = %g\" % r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrainingRandomForest():\n",
    "    trainWithRandomForest(getLearningDataWithFeatureVector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = startTrainingRandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.bestModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWithGBT(X):\n",
    "    train, test = X.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "    rf = GBTRegressor()\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "    # TrainValidationSplit will try all combinations of values and determine best model using\n",
    "    # the evaluator.\n",
    "    paramGrid = ParamGridBuilder()\\\n",
    "        .addGrid(rf.maxIter, [50, 100]) \\\n",
    "        .addGrid(rf.maxDepth, [5])\\\n",
    "        .build()\n",
    "\n",
    "    # In this case the estimator is simply the linear regression.\n",
    "    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "    tvs = CrossValidator(estimator=rf,\n",
    "                               estimatorParamMaps=paramGrid,\n",
    "                               evaluator=RegressionEvaluator())\n",
    "\n",
    "    # Run TrainValidationSplit, and choose the best set of parameters.\n",
    "    model = tvs.fit(train)\n",
    "\n",
    "    # Make predictions on test data. model is the model with combination of parameters\n",
    "    # that performed best.\n",
    "    predictions = model.transform(test)\n",
    "    predictions.select(\"features\", \"label\", \"prediction\")\\\n",
    "        .show()\n",
    "    # return model\n",
    "    #print(\"Linear Regression Result\")\n",
    "    #print(\"RootMeanSquare:\")\n",
    "    #print(model.bestModel.summary.rootMeanSquaredError)\n",
    "    #print(\"R2:\")\n",
    "    #print(model.bestModel.summary.r2)\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2 = evaluator.evaluate(predictions)\n",
    "    print(\"R2 (R2) on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrainingGBT():\n",
    "    trainWithGBT(getLearningDataWithFeatureVector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTrainingGBT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
